{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb723bba-4333-4858-9522-10fc6efee267",
   "metadata": {},
   "source": [
    "# Voice Assistance and Web scrapping(using Parse Hub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56d5669b-f495-45cc-9f8e-3ffbf7df44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important Packagess\n",
    "import requests\n",
    "import json\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n",
    "import re\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88a09e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY= \"Your Api Key",
    "PROJECT_TOKEN=\"Your Project token"\n",
    "RUN_TOKEN=\"Your Run token""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc6bdf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    \n",
    "    def __init__(self,api_key,project_token):\n",
    "            self.api_key = api_key\n",
    "            self.project_token = project_token\n",
    "            self.params={\n",
    "                \"api_key\": self.api_key\n",
    "            }\n",
    "            self.data=self.get_data()\n",
    "    \n",
    "    def get_data(self):\n",
    "        response = requests.get(f'https://www.parsehub.com/api/v2/projects/{PROJECT_TOKEN}/last_ready_run/data',params={\"api_key\":API_KEY})\n",
    "        data=json.loads(response.text)\n",
    "        return data\n",
    "    \n",
    "    def get_total_cases(self):\n",
    "        data=self.data['total']\n",
    "        \n",
    "        for content in data:\n",
    "            if content['name']==\"Active Cases:\":\n",
    "                return content['value']\n",
    "    \n",
    "    \n",
    "    def get_total_deaths(self):\n",
    "        data=self.data['total']\n",
    "        \n",
    "        for content in data:\n",
    "            if content['name']==\"Last Total death:\":\n",
    "                return content['value']\n",
    "        return \"0\"\n",
    "    \n",
    "    \n",
    "    def get_state_data(self,state):\n",
    "        data=self.data[\"state\"]\n",
    "        \n",
    "        for content in data:\n",
    "            if content['name'].lower()==state.lower():\n",
    "                return content\n",
    "        return \"0\"\n",
    "    def get_list_of_states(self):\n",
    "        states=[]\n",
    "        for state in self.data['state']:\n",
    "            states.append(state['name'].lower())\n",
    "        return states\n",
    "    def update_data(self):\n",
    "        response = requests.post(f'https://www.parsehub.com/api/v2/projects/{self.project_token}/run',params=self.params)\n",
    "        #old_data=self.data\n",
    "        \n",
    "        def poll():\n",
    "            time.sleep(0.1)\n",
    "            old_data=self.data\n",
    "            while True:\n",
    "                new_data=self.get_data()\n",
    "                if new_data!=old_data:\n",
    "                    self.data=new_data\n",
    "                    print(\"Data Updated\")\n",
    "                    break\n",
    "                time.sleep(5)\n",
    "        \n",
    "        t=threading.Thread(target=poll)\n",
    "        t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3925f8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['andaman and nicobar', 'andhra pradesh', 'arunachal pradesh', 'assam', 'bihar', 'chandigarh', 'chhattisgarh', 'dadra and nagar haveli and daman and diu', 'delhi', 'goa', 'gujarat', 'haryana', 'himachal pradesh', 'jammu and kashmir', 'jharkhand', 'karnataka', 'kerala', 'ladakh', 'lakshadweep', 'maharashtra', 'manipur', 'meghalaya', 'mizoram', 'madhya pradesh', 'nagaland', 'odisha', 'puducherry', 'punjab', 'rajasthan', 'sikkim', 'tamil nadu', 'telengana', 'tripura', 'uttar pradesh', 'uttarakhand', 'west bengal']\n"
     ]
    }
   ],
   "source": [
    "data=Data(API_KEY,PROJECT_TOKEN)\n",
    "print(data.get_list_of_states())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc4c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mic Testing\n",
    "def speak(text):\n",
    "    engine =pyttsx3.init()\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "#speak(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f5c4a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Speak Recogition\n",
    "def get_audio():\n",
    "    r=sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        audio=r.listen(source,timeout=3,phrase_time_limit=3)    #recording audio\n",
    "        said = \"\"\n",
    "        try:\n",
    "            said=r.recognize_google(audio)\n",
    "        except Exception as e:\n",
    "                print(\"Exception\",str(e))\n",
    "    return said.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "810c3bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print(\"Started Program\")\n",
    "    data=Data(API_KEY,PROJECT_TOKEN)\n",
    "    END_PHRASE=\"stop\"\n",
    "    state_list=data.get_list_of_states()\n",
    "    \n",
    "    \n",
    "    TOTAL_PATTERNS={\n",
    "        re.compile(\"[\\w\\s]+ total [\\w\\s] + cases\"): data.get_total_cases,\n",
    "        re.compile(\"[\\w\\s]+ total cases\"): data.get_total_cases,\n",
    "        re.compile(\"[\\w\\s]+ total [\\w\\s] + deaths\"): data.get_total_deaths,\n",
    "        re.compile(\"[\\w\\s]+ total deaths\"): data.get_total_deaths,\n",
    "    }\n",
    "    \n",
    "    STATE_PATTERN={\n",
    "        re.compile(\"[\\w\\s]+ cases [\\w\\s]+\"): lambda state:data.get_state_data(state)['total_cases'],\n",
    "        re.compile(\"[\\w\\s]+ deaths[\\w\\s]+\"): lambda state:data.get_state_data(state)['total_deaths'],\n",
    "    }\n",
    "    UPDATE_COMMAND=\"update\"\n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        print(\"Listening...\")\n",
    "        text=get_audio()\n",
    "        print(text)\n",
    "        result=None\n",
    "        \n",
    "        for pattern,func in STATE_PATTERN.items():\n",
    "            if pattern.match(text):\n",
    "                words=set(text.split(\" \"))\n",
    "                for state in state_list:\n",
    "                    if state in words:\n",
    "                        result=func(state)\n",
    "                        break\n",
    "        \n",
    "        for pattern,func in TOTAL_PATTERNS.items():\n",
    "            if pattern.match(text):   #match is called becaused regex is used and it compiled\n",
    "                result=func()\n",
    "                break\n",
    "        \n",
    "        if text==UPDATE_COMMAND:\n",
    "            result=\"Data is being updated. This will take some time!\"\n",
    "            data.update_data()\n",
    "            \n",
    "        if result:\n",
    "            speak(result)     #speak result that is being search\n",
    "            print(result)\n",
    "        \n",
    "        if text.find(END_PHRASE)!=-1: #stop loop\n",
    "            print(\"Exit\")\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a065bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Program\n",
      "Listening...\n",
      "update\n",
      "Data is being updated. This will take some time!\n",
      "Listening...\n",
      "abhi ka\n",
      "Listening...\n",
      "Exception \n",
      "\n",
      "Listening...\n",
      "Exception \n",
      "\n",
      "Listening...\n",
      "Exception \n",
      "\n",
      "Listening...\n",
      "stop\n",
      "Exit\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
